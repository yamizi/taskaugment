import os
from comet_ml import Experiment
import torch
import numpy as np
from models.taskonomy_models import resnet18_taskonomy, resnet50_taskonomy
from utils.xception_taskonomy_small import XceptionTaskonomySmall, xception_taskonomy_small
from utils.xception_taskonomy_new import XceptionTaskonomy

COMET_APIKEY = ""
TASKONOMY_DATASET = "~/Code/datasets/taskonomy_small/taskonomy-sample-model-1-small-master"

map_dict = {
        'segmentsemantic'   : 's',
        'edge_texture'      : 'e',
        'depth_zbuffer'     : 'd',
        'autoencoder'       : 'A',
        'edge_occlusion'    : 'E',
        'depth_euclidean'   : 'D',
        'normal'            : 'n',
        'principal_curvature': 'p',
        'reshading'         : 'r',
        'keypoints2d'       : 'k',
        'keypoints3d'       : 'K'
    }



def abbrev_to_task(l):
        if not l:
                return l
        inverse_dict = dict(zip(map_dict.values(), map_dict.keys()))
        tasks = [inverse_dict.get(e,None) for e in l if inverse_dict.get(e,None)]
        return tasks

def load_model(args):
        train = [map_dict[e] for e in args.train_task_set]
        aux = [map_dict.get(e,"") for e in args.aux_task_set]
        test = [map_dict[e] for e in args.test_task_set]

        epoch = args.epoch

        # path_model = os.path.join(args.model_root, "savecheckpoint","checkpoint_{epoch}.pth.tar").format(
        #         arch=args.arch,
        #         dataset=args.dataset,
        #         train="".join(train),
        #         aux="".join(aux),
        #         test="".join(test),
        #         epoch=epoch
        # )

        # path_model=  path_model.replace("\r","")
        path_model = args.model_root

        if args.dataset == "taskonomy" and args.arch == "resnet18":
                model = resnet18_taskonomy(pretrained=False, tasks=args.test_task_set)

        elif args.dataset == "taskonomy" and args.arch == "resnet50":
                model = resnet50_taskonomy(pretrained=False, tasks=args.test_task_set)

        elif args.dataset == "taskonomy" and args.arch == "xception":
                model = xception_taskonomy_small(pretrained=False, tasks=args.test_task_set)
                #XceptionTaskonomySmall(tasks=args.test_task_set)


        elif args.dataset == "taskonomy" and args.arch == 'wresnet50':
                from models.taskonomy_models import wide_resnet50_2
                model = wide_resnet50_2(pretrained=False, tasks=args.test_task_set)

        elif args.dataset == "taskonomy" and args.arch == 'wresnet101':
                from models.taskonomy_models import wide_resnet101_2
                model = wide_resnet101_2(pretrained=False, tasks=args.test_task_set)

        elif args.dataset == "taskonomy" and args.arch == 'resnet152':
                from models.taskonomy_models import resnet152_taskonomy
                model = resnet152_taskonomy(pretrained=False, tasks=args.test_task_set)

        elif args.dataset == "taskonomy" and args.arch == 'xception-full':
                model = XceptionTaskonomy(tasks=args.test_task_set)

        if torch.cuda.is_available():
                checkpoint_model = torch.load(path_model)
        else:
                checkpoint_model = torch.load(path_model, map_location=lambda storage, loc: storage)

        state = checkpoint_model['state_dict']


        if False: # args.arch =="xception":
                for name,weight in state.items():
                        if 'pointwise' in name:
                                state[name]=weight.unsqueeze(-1).unsqueeze(-1)
                        if 'conv1' in name and len(weight.shape)!=4:
                                state[name]=weight.unsqueeze(1)

        else:
                ks = list(state.keys())
                for k in ks:
                        state[k[7:]] = state.pop(k)

        model.load_state_dict(state, strict=False)  # , strict=False
        model = torch.nn.DataParallel(model)
        if torch.cuda.is_available():
                model.cuda()

        return model


def init_comet(args, project_name="robust-mlt"):
        experiment_name = "{}_{}_{}_{}".format(args.dataset, args.arch, "".join(args.target_task_set), args.timestamp)
        experiment = Experiment(api_key=COMET_APIKEY,
                                project_name=project_name,
                                workspace="yamizi",
                                auto_param_logging=False, auto_metric_logging=False,
                                parse_args=False, display_summary=False, disabled=False)

        experiment.set_name(experiment_name)
        experiment.log_parameters(vars(args))

        return experiment
